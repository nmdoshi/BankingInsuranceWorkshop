{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\n!pip install --user dd-scenario\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\nfrom dd_scenario import *\n\n# Creates a client...\n# If you want to be able to call solve() on the client, you have to provide your API Key\n# client = Client(pc=pc, apikey='IAM_APIKEY')\nclient = Client(pc=pc)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "#dd-ignore\n\n#Get 'Loan Department' decision...\ndd_model_builder = client.get_model_builder(name=\"Loan Department\")\n\n#Get scenario 'ScheduleActivities'...\nscenario = dd_model_builder.get_scenario(name=\"ScheduleActivities\")\n\n#Load all input data as a map { data_name: data_frame }\ninputs = scenario.get_tables_data(category='input')\n# This will hold all outputs as a map { data_name: data_frame }\noutputs = {}\n\n# we use a lock to access ``outputs``. This allows solves() to\n# be aborted without race condition in data writting\nimport threading\noutput_lock = threading.Lock()\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": "from docplex.mp.utils import *\nfrom docplex.cp.model import *\nfrom docplex.cp.expression import _FLOATING_POINT_PRECISION\nfrom docplex.util.environment import get_environment\nimport time\nimport operator\n\nimport pandas as pd\nimport numpy as np\nimport math\n\nimport codecs\nimport sys\n\n# Handle output of unicode strings\nif sys.version_info[0] < 3:\n    sys.stdout = codecs.getwriter('utf8')(sys.stdout)\n\n\n# Convert type to 'int64'\ndef helper_int64_convert(arg):\n    if pd.__version__ < '0.20.0':\n        return arg.astype('int64', raise_on_error=False)\n    else:\n        return arg.astype('int64', errors='ignore')\n\n# Parse and convert an integer Series to a date Series\n# Integer value represents the number of schedule units (time granularity for engine) since horizon start\ndef helper_convert_int_series_to_date(sched_int_series):\n    return pd.to_datetime(sched_int_series * secs_per_day / duration_units_per_day / schedUnitPerDurationUnit * nanosecs_per_sec + horizon_start_date.value, errors='coerce')\n\n# Convert a duration Series to a Series representing the number of scheduling units\ndef helper_convert_duration_series_to_scheduling_unit(duration_series, nb_input_data_units_per_day):\n    return helper_int64_convert(duration_series * duration_units_per_day * schedUnitPerDurationUnit / nb_input_data_units_per_day)\n\ndef helper_get_column_name_for_property(property):\n    return helper_property_id_to_column_names_map.get(property, 'unknown')\n\n\n# Parse and convert a date to an integer\n# Integer value represents the number of schedule units (time granularity for engine) since horizon start\ndef helper_convert_date_to_int(date):\n    return int((date - horizon_start_date).value / nanosecs_per_sec * duration_units_per_day * schedUnitPerDurationUnit / secs_per_day)\n\n\ndef helper_parse_and_convert_date_to_int(date_as_str):\n    return helper_convert_date_to_int(pd.to_datetime(date_as_str))\n\n# Label constraint\nexpr_counter = 1\ndef helper_add_labeled_cpo_constraint(mdl, expr, label, context=None, columns=None):\n    global expr_counter\n    if isinstance(expr, np.bool_):\n        expr = expr.item()\n    if isinstance(expr, bool):\n        pass  # Adding a trivial constraint: if infeasible, docplex will raise an exception it is added to the model\n    else:\n        expr.name = '_L_EXPR_' + str(expr_counter)\n        expr_counter += 1\n        if columns:\n            ctxt = \", \".join(str(getattr(context, col)) for col in columns)\n        else:\n            if context:\n                ctxt = context.Index if isinstance(context.Index, str) is not None else \", \".join(context.Index)\n            else:\n                ctxt = None\n        expr_to_info[expr.name] = (label, ctxt)\n    mdl.add(expr)\n\ndef helper_get_index_names_for_type(dataframe, type):\n    if not is_pandas_dataframe(dataframe):\n        return None\n    return [name for name in dataframe.index.names if name in helper_concept_id_to_index_names_map.get(type, [])]\n\n\nhelper_concept_id_to_index_names_map = {\n    'cTask': ['id_of_Activity'],\n    'LoanOfficers': ['id_of_LoanOfficers'],\n    'Activity': ['id_of_Activity'],\n    'cUnaryResource': ['id_of_LoanOfficers']}\nhelper_property_id_to_column_names_map = {\n    'Activity.Duration in days': 'Duration_in_days',\n    'Activity.Activity': 'Activity',\n    'cTask.fixedDuration': 'Duration_in_days',\n    'LoanOfficers.Name': 'Name'}\n\n\n# Data model definition for each table\n# Data collection: list_of_Activity ['Duration_in_days', 'Activity']\n# Data collection: list_of_LoanOfficers ['Name']\n\n# Create a pandas Dataframe for each data table\nlist_of_Activity = inputs[u'Activity']\nlist_of_Activity = list_of_Activity[[u'Duration in days', u'Activity']].copy()\nlist_of_Activity.rename(columns={u'Duration in days': 'Duration_in_days', u'Activity': 'Activity'}, inplace=True)\nlist_of_LoanOfficers = inputs[u'LoanOfficers']\nlist_of_LoanOfficers = list_of_LoanOfficers[[u'Name']].copy()\nlist_of_LoanOfficers.rename(columns={u'Name': 'Name'}, inplace=True)\n\n# Set index when a primary key is defined\nlist_of_Activity.set_index('Activity', inplace=True)\nlist_of_Activity.sort_index(inplace=True)\nlist_of_Activity.index.name = 'id_of_Activity'\nlist_of_LoanOfficers.set_index('Name', inplace=True)\nlist_of_LoanOfficers.sort_index(inplace=True)\nlist_of_LoanOfficers.index.name = 'id_of_LoanOfficers'\n# Define time granularity for scheduling\nschedUnitPerDurationUnit = 1440  # DurationUnit is days\nduration_units_per_day = 1.0\n\n\n# Define global constants for date to integer conversions\nhorizon_start_date = pd.to_datetime('Wed Jul 25 00:00:00 UTC 2018')\nhorizon_end_date = horizon_start_date + pd.Timedelta(days=3650)\nnanosecs_per_sec = 1000.0 * 1000 * 1000\nsecs_per_day = 3600.0 * 24\n\n# Convert all input durations to internal time unit\nlist_of_Activity['INTERNAL_RAW_Duration_in_days'] = list_of_Activity['Duration_in_days']\nlist_of_Activity['Duration_in_days'] = helper_convert_duration_series_to_scheduling_unit(list_of_Activity.Duration_in_days, 1.0)\n\n\n# Create data frame as cartesian product of: Activity x LoanOfficers\nlist_of_SchedulingAssignment = pd.DataFrame(index=pd.MultiIndex.from_product((list_of_Activity.index, list_of_LoanOfficers.index), names=['id_of_Activity', 'id_of_LoanOfficers']))\n\n\n\n\ndef build_model():\n    mdl = CpoModel()\n\n    # Definition of model variables\n    list_of_SchedulingAssignment['interval'] = interval_var_list(len(list_of_SchedulingAssignment), end=(INTERVAL_MIN, helper_convert_date_to_int(horizon_end_date)), optional=True)\n    list_of_SchedulingAssignment['schedulingAssignmentVar'] = list_of_SchedulingAssignment.interval.apply(mdl.presence_of)\n    list_of_Activity['interval'] = interval_var_list(len(list_of_Activity), end=(INTERVAL_MIN, helper_convert_date_to_int(horizon_end_date)), optional=True)\n    list_of_Activity['taskStartVar'] = list_of_Activity.interval.apply(mdl.start_of)\n    list_of_Activity['taskEndVar'] = list_of_Activity.interval.apply(mdl.end_of)\n    list_of_Activity['taskDurationVar'] = list_of_Activity.interval.apply(mdl.size_of)\n    list_of_Activity['taskAbsenceVar'] = 1 - list_of_Activity.interval.apply(mdl.presence_of)\n    list_of_Activity['taskPresenceVar'] = list_of_Activity.interval.apply(mdl.presence_of)\n\n\n    # Definition of model\n    # Objective cMinimizeMakespan-\n    # Combine weighted criteria: \n    # \tcMinimizeMakespan cMinimizeMakespan 1.2{\n    # \ttask = Activity,\n    # \tscaleFactorExpr = 1,\n    # \t(static) goalFilter = null,\n    # \t(static) taskEnd = decisionPath(cTaskEnd[Activity]),\n    # \t(static) numericExpr = max of decisionPath(cTaskEnd[Activity]) over cTaskEnd[Activity]} with weight 5.0\n    agg_Activity_taskEndVar_SG1 = mdl.max(list_of_Activity.taskEndVar)\n    \n    kpis_expression_list = [\n        (1, 1.0, agg_Activity_taskEndVar_SG1 / schedUnitPerDurationUnit, 1, 0, u'time to complete all Activities')]\n    custom_code.update_goals_list(kpis_expression_list)\n    \n    for i, (_, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name) in enumerate(kpis_expression_list):\n        kpi_var = integer_var(name='kpi_' + repr(i + 1))\n        mdl.add(kpi_var >= kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset) - 1 + _FLOATING_POINT_PRECISION)\n        mdl.add(kpi_var <= kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset))\n        mdl.add_kpi(kpi_var, name=kpi_name)\n    \n    mdl.add(minimize(sum([kpi_sign * kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset) for kpi_sign, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name in kpis_expression_list])))\n    \n    # [ST_1] Constraint : cLimitNumberOfResourcesAssignedToEachActivitySched_cIterativeRelationalConstraint\n    # The number of LoanOfficers assignments for each Activity is equal to 1\n    # Label: CT_1_The_number_of_LoanOfficers_assignments_for_each_Activity_is_equal_to_1\n    groupbyLevels = ['id_of_Activity']\n    groupby_SchedulingAssignment = list_of_SchedulingAssignment.schedulingAssignmentVar.groupby(level=groupbyLevels).sum().to_frame()\n    for row in groupby_SchedulingAssignment.itertuples(index=True):\n        helper_add_labeled_cpo_constraint(mdl, row.schedulingAssignmentVar == 1, u'The number of LoanOfficers assignments for each Activity is equal to 1', row)\n    \n    # [ST_2] Constraint : cSetFixedDurationSpezProp_cSetFixedDurationPath\n    # The schedule must respect the duration specified for each Activity\n    # Label: CT_2_The_schedule_must_respect_the_duration_specified_for_each_Activity\n    for row in list_of_Activity[list_of_Activity.Duration_in_days.notnull()].itertuples(index=True):\n        helper_add_labeled_cpo_constraint(mdl, size_of(row.interval, int(row.Duration_in_days)) == int(row.Duration_in_days), u'The schedule must respect the duration specified for each Activity', row)\n    \n    # [ST_3] Constraint : cForceTaskPresence_cIterativeRelationalConstraint\n    # All Activities are scheduled\n    # Label: CT_3_All_Activities_are_scheduled\n    for row in list_of_Activity.itertuples(index=True):\n        helper_add_labeled_cpo_constraint(mdl, row.taskAbsenceVar != 1, u'All Activities are scheduled', row)\n    \n    # Scheduling internal structure\n    groupby_SchedulingAssignment = list_of_SchedulingAssignment.reset_index()[['id_of_Activity', 'interval']].groupby(['id_of_Activity'])['interval'].apply(list).to_frame()\n    join_SchedulingAssignment = groupby_SchedulingAssignment.join(list_of_Activity.interval, rsuffix='_right', how='inner')\n    for row in join_SchedulingAssignment.itertuples(index=False):\n        mdl.add(synchronize(row.interval_right, row.interval))\n    \n    # link presence if not alternative\n    groupby_SchedulingAssignment = list_of_SchedulingAssignment.schedulingAssignmentVar.groupby(level=['id_of_Activity']).agg(lambda l: mdl.max(l.tolist())).to_frame()\n    join_SchedulingAssignment = groupby_SchedulingAssignment.join(list_of_Activity.taskPresenceVar, how='inner')\n    for row in join_SchedulingAssignment.itertuples(index=False):\n        mdl.add(row.schedulingAssignmentVar <= row.taskPresenceVar)\n    \n    # no overlap\n    groupby_SchedulingAssignment = list_of_SchedulingAssignment.reset_index()[['id_of_LoanOfficers', 'interval']].groupby(['id_of_LoanOfficers'])['interval'].apply(list).to_frame()\n    for row in groupby_SchedulingAssignment.reset_index().itertuples(index=False):\n        mdl.add(no_overlap(row.interval))\n\n\n    return mdl\n\n\ndef solve_model(mdl):\n    params = CpoParameters()\n    params.TimeLimit = 120\n    # Call to custom code to update parameters value\n    custom_code.update_solver_params(params)\n    # Update parameters value according to environment variables definition\n    cpo_param_env_prefix = 'ma.cpo.'\n    cpo_params = [name[4:] for name in dir(CpoParameters) if name.startswith('set_')]\n    for param in cpo_params:\n        env_param = cpo_param_env_prefix + param\n        param_value = get_environment().get_parameter(env_param)\n        if param_value:\n            # Updating parameter value\n            print(\"Updated value for parameter %s = %s\" % (param, param_value))\n            params[param] = param_value\n\n    solver = CpoSolver(mdl, params=params, trace_log=True)\n    try:\n        for i, msol in enumerate(solver):\n            ovals = msol.get_objective_values()\n            print(\"Objective values: {}\".format(ovals))\n            # Initialize dict iterator that works in Py2.7 and Py3\n            kpis_dict = msol.get_kpis()\n            kpis_iterator = getattr(kpis_dict, \"viewitems\", None)\n            if not kpis_iterator:\n                kpis_iterator = kpis_dict.items\n            for k, v in kpis_iterator():\n                print('%s --> %s' % (k, v))\n            export_solution(msol)\n            if ovals is None:\n                break  # No objective: stop after first solution\n        # If model is infeasible, invoke conflict refiner to return\n        if solver.get_last_solution().get_solve_status() == SOLVE_STATUS_INFEASIBLE:\n            conflicts = solver.refine_conflict()\n            export_conflicts(conflicts)\n    except CpoException as e:\n        # Solve has been aborted from an external action\n        print('An exception has been raised: %s' % str(e))\n        raise e\n\n\nexpr_to_info = {}\n\n\ndef export_conflicts(conflicts):\n    # Display conflicts in console\n    print('Conflict set:')\n    list_of_conflicts = pd.DataFrame(columns=['constraint', 'context', 'detail'])\n    for item, index in zip(conflicts.member_constraints, range(len(conflicts.member_constraints))):\n        label, context = expr_to_info.get(item.name, ('N/A', item.name))\n        constraint_detail = expression._to_string(item)\n        # Print conflict information in console\n        print(\"Conflict involving constraint: %s, \\tfor: %s -> %s\" % (label, context, constraint_detail))\n        list_of_conflicts = list_of_conflicts.append(pd.DataFrame({'constraint': label, 'context': str(context), 'detail': constraint_detail},\n                                                                  index=[index], columns=['constraint', 'context', 'detail']))\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_conflicts'] = list_of_conflicts\n\n\ndef export_solution(msol):\n    start_time = time.time()\n    list_of_SchedulingAssignment_solution = pd.DataFrame(index=list_of_SchedulingAssignment.index)\n    list_of_SchedulingAssignment_solution['schedulingAssignmentVar'] = list_of_SchedulingAssignment.interval.apply(lambda r: (1 if msol.solution.get_var_solution(r).is_present() else 0) if msol.solution.get_var_solution(r) else np.NaN)\n    list_of_Activity_solution = pd.DataFrame(index=list_of_Activity.index)\n    list_of_Activity_solution = list_of_Activity_solution.join(pd.DataFrame([msol.solution[interval] if msol.solution[interval] else (None, None, None) for interval in list_of_Activity.interval], index=list_of_Activity.index, columns=['taskStartVar', 'taskEndVar', 'taskDurationVar']))\n    list_of_Activity_solution['taskStartVarDate'] = helper_convert_int_series_to_date(list_of_Activity_solution.taskStartVar)\n    list_of_Activity_solution['taskEndVarDate'] = helper_convert_int_series_to_date(list_of_Activity_solution.taskEndVar)\n    list_of_Activity_solution.taskStartVar /= schedUnitPerDurationUnit\n    list_of_Activity_solution.taskEndVar /= schedUnitPerDurationUnit\n    list_of_Activity_solution.taskDurationVar /= schedUnitPerDurationUnit\n    list_of_Activity_solution['taskAbsenceVar'] = list_of_Activity.interval.apply(lambda r: (1 if msol.solution.get_var_solution(r).is_absent() else 0) if msol.solution.get_var_solution(r) else np.NaN)\n    list_of_Activity_solution['taskPresenceVar'] = list_of_Activity.interval.apply(lambda r: (1 if msol.solution.get_var_solution(r).is_present() else 0) if msol.solution.get_var_solution(r) else np.NaN)\n\n    # Filter rows for non-selected assignments\n    list_of_SchedulingAssignment_solution = list_of_SchedulingAssignment_solution[list_of_SchedulingAssignment_solution.schedulingAssignmentVar > 0.5]\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_Activity_solution'] = list_of_Activity_solution.reset_index()\n        outputs['list_of_SchedulingAssignment_solution'] = list_of_SchedulingAssignment_solution.reset_index()\n        custom_code.post_process_solution(msol, outputs)\n\n    elapsed_time = time.time() - start_time\n    print('solution export done in ' + str(elapsed_time) + ' secs')\n    return\n\n\n# Instantiate CustomCode class if definition exists\ntry:\n    custom_code = CustomCode(globals())\nexcept NameError:\n    # Create a dummy anonymous object for custom_code\n    custom_code = type('', (object,), {'preprocess': (lambda *args: None),\n                                       'update_goals_list': (lambda *args: None),\n                                       'update_model': (lambda *args: None),\n                                       'update_solver_params': (lambda *args: None),\n                                       'post_process_solution': (lambda *args: None)})()\n\n# Custom pre-process\ncustom_code.preprocess()\n\nprint('* building wado model')\nstart_time = time.time()\nmodel = build_model()\n\n# Model customization\ncustom_code.update_model(model)\n\nelapsed_time = time.time() - start_time\nprint('model building done in ' + str(elapsed_time) + ' secs')\n\nprint('* running wado model')\nstart_time = time.time()\nsolve_model(model)\nelapsed_time = time.time() - start_time\nprint('solve + export of all intermediate solutions done in ' + str(elapsed_time) + ' secs')"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}